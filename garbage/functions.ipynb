{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acbbb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn. preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02070194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(data): \n",
    "    ## maybe balance the number of tweets from each?\n",
    "    dfH = data.loc[data['Candidate']=='HC',:]\n",
    "    #print(\"HC length: \",len(dfH))\n",
    "\n",
    "    dfT =data.loc[data['Candidate']=='DT',:]\n",
    "    #print(\"DT length: \",len(dfT))\n",
    "    df_new = data\n",
    "    A = len(dfT)\n",
    "    B = len(dfH)\n",
    "    \n",
    "    if B>A: \n",
    "        print('look at function \"balance_data\"')\n",
    "    missing_rows = A-B\n",
    "    row_fraction = missing_rows/A\n",
    "    for i in range(math.floor(row_fraction)):\n",
    "        df_new = df_new.append(dfH)\n",
    "        \n",
    "    leftover = row_fraction - math.floor(row_fraction)\n",
    "    df_new = df_new.append(dfH[:math.floor(len(dfH)*leftover)])\n",
    "\n",
    "    print(\"DT length ratio: \",len(dfT)/len(df_new))\n",
    "\n",
    "    data = df_new\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9fbbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training (model, x_train,y_train,param_grid): \n",
    "    CVM = GridSearchCV(\n",
    "        model, param_grid = param_grid\n",
    "        )\n",
    "\n",
    "    CVM.fit(X_train,Y_train)\n",
    "    return CVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dbdb821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,name, data_name):\n",
    "    filename = name+'_GS_'+data_name\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f814441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(filename ): \n",
    "    loaded_model = pickle.load(open(filename, 'rb'))\n",
    "    print(filename+\" results on test data\")\n",
    "    print(\"roc_auc:\",roc_auc_score(Y_test,loaded_model.predict(X_test)))\n",
    "    print(\"accurarcy:\",accuracy_score(Y_test,loaded_model.predict(X_test)))\n",
    "    print(\"note 1 is Donald Trump\")\n",
    "    cm = confusion_matrix(Y_test,loaded_model.predict(X_test))\n",
    "    ConfusionMatrixDisplay(cm).plot()\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9f5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_MDI_importance(X_train,Y_train,loaded_model,name): \n",
    "    \n",
    "    if name == \"Extra Trees\":\n",
    "        MOD = ExtraTreesClassifier(n_estimators =loaded_model.best_params_['n_estimators'],random_state = loaded_model.best_params_['random_state'] )\n",
    "    elif name == \"Random Forest\":\n",
    "        MOD = GridSearchCV(RandomForestClassifier(n_estimators =loaded_model.best_params_['n_estimators'],\n",
    "                                                  random_state = loaded_model.best_params_['random_state'],\n",
    "                                                  max_depth = loaded_model.best_params_['max_depth']))\n",
    "        \n",
    "    \n",
    "    MOD.fit(X_train,Y_train)\n",
    "    ## is there a better way to do this than a bigggg if else   \n",
    "        \n",
    "    importances = MOD.feature_importances_\n",
    "    std = np.std([MOD.feature_importances_ for tree in MOD.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)\n",
    "    feature_list = [X.columns[indices[f]] for f in range(X.shape[1])]  #names of features. ## may have to be X)train\n",
    "    ff = np.array(feature_list)\n",
    "                           \n",
    "    '''\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f) name: %s\" % (f + 1, indices[f], importances[indices[f]], ff[indices[f]]))\n",
    "    '''\n",
    "\n",
    "    plt.figure()\n",
    "    plt.rcParams['figure.figsize'] = [16, 6]\n",
    "    plt.title(\"Feature importances using Mean Decrease in Impurity\")## MDI\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), ff[indices], rotation=90)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da15593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_permutation_feature_importance(model):\n",
    "    scoring = ['roc_auc', 'accuracy']#\n",
    "    r_multi = permutation_importance(\n",
    "        model, X_test, Y_test, n_repeats=30, random_state=0, scoring=scoring)\n",
    "\n",
    "    features= list(twitter.columns)[6:-2]\n",
    "    roc_auc_importance = []\n",
    "    roc_auc_std = []\n",
    "    acc_importance =[]\n",
    "    acc_std=[]\n",
    "    for metric in r_multi:\n",
    "        print(f\"{metric}\")\n",
    "        r = r_multi[metric]\n",
    "        for i in range(len(features)):\n",
    "            #if r.importances_mean[i] - 2 * r.importances_std[i] > 0: ## do we want to know this?\n",
    "            print(i,f\"    {list(twitter.columns)[6:-2][i]:<8}\"\n",
    "                  f\"{r.importances_mean[i]:.3f}\"\n",
    "                  f\" +/- {r.importances_std[i]:.3f}\")\n",
    "            if metric == 'roc_auc':\n",
    "                roc_auc_importance.append(r.importances_mean[i])\n",
    "                roc_auc_std.append(r.importances_std[i])\n",
    "            if metric == 'accuracy': \n",
    "                acc_importance.append(r.importances_mean[i])\n",
    "                acc_std.append(r.importances_std[i])\n",
    "\n",
    "    d = {'features': features, 'acc_importance': acc_importance, 'roc_auc_importance': roc_auc_importance}\n",
    "    acc_importance_df = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 4))# this adjusts how far away the plots are from eachother\n",
    "\n",
    "    ax = plt.subplot(221)\n",
    "\n",
    "    acc_importance_df = acc_importance_df.sort_values(by = 'acc_importance')\n",
    "    acc_importance_df.plot(x = 'features', y ='acc_importance', kind = 'bar',ax = ax)\n",
    "    plt.xticks(rotation = 'vertical')\n",
    "    ax.set_title(\"Feature importance of Random Forest based on accuracy\")\n",
    "    ax.set_ylabel(\"permutation importance\")\n",
    "\n",
    "    ax = plt.subplot(222)\n",
    "    acc_importance_df = acc_importance_df.sort_values(by = 'roc_auc_importance')\n",
    "    acc_importance_df.plot(x = 'features', y ='roc_auc_importance', kind = 'bar', ax =ax)\n",
    "    plt.xticks(rotation = 'vertical')\n",
    "    ax.set_title(\"Feature importance of Random Forest based on roc_auc\")\n",
    "    ax.set_ylabel(\"permutation importance\")   \n",
    "    \n",
    "    ax = plt.subplot(223)\n",
    "    roc_df.plot(kind = \"box\",ax =ax)\n",
    "    plt.xticks(rotation = 'vertical')\n",
    "    ax.set_title(\"Feature importance of Random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16818de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inital code: \n",
    "\n",
    "'''\n",
    "ax = plt.subplot(223)\n",
    "roc_df.plot(kind = \"box\",ax =ax)\n",
    "plt.xticks(rotation = 'vertical')\n",
    "ax.set_title(\"Feature importance of Random\")\n",
    "\n",
    "\n",
    "acc_importance_df = acc_importance_df.sort_values(by = 'acc_importance')\n",
    "    acc_importance_df.plot(x = 'features', y ='acc_importance', kind = 'bar',ax = ax)\n",
    "    plt.xticks(rotation = 'vertical')\n",
    "    ax.set_title(\"Feature importance of Random)'''\n",
    "########\n",
    "'''\n",
    "\n",
    "scoring = ['roc_auc', 'accuracy']#\n",
    "r_multi = permutation_importance(\n",
    "    ETCV, X_test, Y_test, n_repeats=30, random_state=0, scoring=scoring)\n",
    "\n",
    "features= list(twitter.columns)[6:-2]\n",
    "roc_auc_importance = []\n",
    "roc_auc_std = []\n",
    "acc_importance =[]\n",
    "acc_std=[]\n",
    "for metric in r_multi:\n",
    "    print(f\"{metric}\")\n",
    "    r = r_multi[metric]\n",
    "    for i in range(len(features)):\n",
    "        #if r.importances_mean[i] - 2 * r.importances_std[i] > 0: ## do we want to know this?\n",
    "        print(i,f\"    {list(twitter.columns)[6:-2][i]:<8}\"\n",
    "              f\"{r.importances_mean[i]:.3f}\"\n",
    "              f\" +/- {r.importances_std[i]:.3f}\")\n",
    "        if metric == 'roc_auc':\n",
    "            roc_auc_importance.append(r.importances_mean[i])\n",
    "            roc_auc_std.append(r.importances_std[i])\n",
    "        if metric == 'accuracy': \n",
    "            acc_importance.append(r.importances_mean[i])\n",
    "            acc_std.append(r.importances_std[i])\n",
    "\n",
    "\n",
    "d = {'features': features, 'acc_importance': acc_importance, 'roc_auc_importance': roc_auc_importance}\n",
    "acc_importance_df = pd.DataFrame(d)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 4))# this adjusts how far away the plots are from eachother\n",
    "\n",
    "ax = plt.subplot(121)\n",
    "\n",
    "acc_importance_df = acc_importance_df.sort_values(by = 'acc_importance')\n",
    "acc_importance_df.plot(x = 'features', y ='acc_importance', kind = 'bar',ax = ax)\n",
    "plt.xticks(rotation = 'vertical')\n",
    "ax.set_title(\"Feature importance of Random Forest based on accuracy\")\n",
    "ax.set_ylabel(\"permutation importance\")\n",
    "\n",
    "ax = plt.subplot(122)\n",
    "acc_importance_df = acc_importance_df.sort_values(by = 'roc_auc_importance')\n",
    "acc_importance_df.plot(x = 'features', y ='roc_auc_importance', kind = 'bar', ax =ax)\n",
    "plt.xticks(rotation = 'vertical')\n",
    "ax.set_title(\"Feature importance of Random Forest based on roc_auc\")\n",
    "ax.set_ylabel(\"permutation importance\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18856eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#source: https://stackoverflow.com/questions/50201913/using-scikit-learn-to-determine-feature-importances-per-class-in-a-rf-model\\n\\n## we first need to make a regular model with the best params that were found.\\n\\n\\n\\n\\n## feature importance for each candidate \\n\\nimportances = ET.feature_importances_\\nstd = np.std([ET.feature_importances_ for tree in ET.estimators_],\\n             axis=0)\\nindices = np.argsort(importances)[::-1]\\nfeature_list = [X.columns[indices[f]] for f in range(X.shape[1])]  #names of features.\\nff = np.array(feature_list)\\n\\nprint(\"Feature ranking:\")\\n\\nfor f in range(X.shape[1]):\\n    print(\"%d. feature %d (%f) name: %s\" % (f + 1, indices[f], importances[indices[f]], ff[indices[f]]))\\n\\n    \\nplt.figure()\\nplt.rcParams[\\'figure.figsize\\'] = [16, 6]\\nplt.title(\"Feature importances\")\\nplt.bar(range(X.shape[1]), importances[indices],\\n       color=\"r\", yerr=std[indices], align=\"center\")\\nplt.xticks(range(X.shape[1]), ff[indices], rotation=90)\\nplt.xlim([-1, X.shape[1]])\\nplt.show()\\n\\ndef class_feature_importance(X, Y, feature_importances):\\n    N, M = X.shape\\n    X = scale(X)\\n\\n    out = {}\\n    for c in set(Y):\\n        out[c] = dict(\\n            zip(range(M), np.mean(X[Y==c, :], axis=0)*feature_importances)\\n        )\\n\\n    return out\\n\\n\\nresult = class_feature_importance(X_train, Y_train, importances)\\n\\ntitles = [\"Did not Divert\", \"Diverted\"]\\nfor t, i in zip(titles, range(len(result))):\\n    plt.figure()\\n    plt.rcParams[\\'figure.figsize\\'] = [16, 6]\\n    plt.title(t)\\n    plt.bar(range(len(result[i])), result[i].values(),\\n           color=\"r\", align=\"center\")\\n    plt.xticks(range(len(result[i])), ff[list(result[i].keys())], rotation=90)\\n    plt.xlim([-1, len(result[i])])\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\\\n",
    "#source: https://stackoverflow.com/questions/50201913/using-scikit-learn-to-determine-feature-importances-per-class-in-a-rf-model\n",
    "\n",
    "## we first need to make a regular model with the best params that were found.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## feature importance for each candidate \n",
    "\n",
    "importances = ET.feature_importances_\n",
    "std = np.std([ET.feature_importances_ for tree in ET.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_list = [X.columns[indices[f]] for f in range(X.shape[1])]  #names of features.\n",
    "ff = np.array(feature_list)\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f) name: %s\" % (f + 1, indices[f], importances[indices[f]], ff[indices[f]]))\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.rcParams['figure.figsize'] = [16, 6]\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), ff[indices], rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "def class_feature_importance(X, Y, feature_importances):\n",
    "    N, M = X.shape\n",
    "    X = scale(X)\n",
    "\n",
    "    out = {}\n",
    "    for c in set(Y):\n",
    "        out[c] = dict(\n",
    "            zip(range(M), np.mean(X[Y==c, :], axis=0)*feature_importances)\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "result = class_feature_importance(X_train, Y_train, importances)\n",
    "\n",
    "titles = [\"Did not Divert\", \"Diverted\"]\n",
    "for t, i in zip(titles, range(len(result))):\n",
    "    plt.figure()\n",
    "    plt.rcParams['figure.figsize'] = [16, 6]\n",
    "    plt.title(t)\n",
    "    plt.bar(range(len(result[i])), result[i].values(),\n",
    "           color=\"r\", align=\"center\")\n",
    "    plt.xticks(range(len(result[i])), ff[list(result[i].keys())], rotation=90)\n",
    "    plt.xlim([-1, len(result[i])])\n",
    "    plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
