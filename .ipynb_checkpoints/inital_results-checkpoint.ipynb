{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\theot\\appdata\\roaming\\python\\python39\\site-packages (1.0.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\theot\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\theot\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\theot\\anaconda3\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\theot\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "GqbM1O-Skh3S"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import io\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "JCelvIz-kmnV"
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "qybV775VpUZ3",
    "outputId": "e95ff704-d601-40db-887d-e3912100001a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## load dataset \\nfrom google.colab import files\\nuploaded = files.upload()\\n'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## load dataset \n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "Y8cEzeiQknGo",
    "outputId": "2fdf1e78-e446-4825-9f37-b1269d63700a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Propaganda Segments</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Name_Calling,Labeling</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Exaggeration,Minimisation</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>...</th>\n",
       "      <th>Flag-Waving</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Slogans</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Black-and-White_Fallacy</th>\n",
       "      <th>Thought-terminating_Cliches</th>\n",
       "      <th>Whataboutism,Straw_Men,Red_Herring</th>\n",
       "      <th>Obfuscation,Intentional_Vagueness,Confusion</th>\n",
       "      <th>Bandwagon,Reductio_ad_hitlerum</th>\n",
       "      <th>Num Prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>On National #VoterRegistrationDay, make sure y...</td>\n",
       "      <td>we can #MakeAmericaGreatAgain: Repetition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>Hillary Clinton's Campaign Continues To Make F...</td>\n",
       "      <td>Make False Claims: Loaded_Language</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>'CNBC, Time magazine online polls say Donald T...</td>\n",
       "      <td>MAGA: Repetition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>In the last 24 hrs. we have raised over $13M f...</td>\n",
       "      <td>Thank you America: Repetition, \"MAGA\": Repetition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>Well, now they're saying that I not only won t...</td>\n",
       "      <td>Nice: Loaded_Language</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    File Name Candidate  \\\n",
       "0           0  DT0_500.txt        DT   \n",
       "1           1  DT0_500.txt        DT   \n",
       "2           2  DT0_500.txt        DT   \n",
       "3           3  DT0_500.txt        DT   \n",
       "4           4  DT0_500.txt        DT   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  On National #VoterRegistrationDay, make sure y...   \n",
       "1  Hillary Clinton's Campaign Continues To Make F...   \n",
       "2  'CNBC, Time magazine online polls say Donald T...   \n",
       "3  In the last 24 hrs. we have raised over $13M f...   \n",
       "4  Well, now they're saying that I not only won t...   \n",
       "\n",
       "                                 Propaganda Segments  Loaded_Language  \\\n",
       "0          we can #MakeAmericaGreatAgain: Repetition              NaN   \n",
       "1                 Make False Claims: Loaded_Language              1.0   \n",
       "2                                   MAGA: Repetition              NaN   \n",
       "3  Thank you America: Repetition, \"MAGA\": Repetition              NaN   \n",
       "4                              Nice: Loaded_Language              1.0   \n",
       "\n",
       "   Name_Calling,Labeling  Repetition  Exaggeration,Minimisation  Doubt  ...  \\\n",
       "0                    NaN         1.0                        NaN    NaN  ...   \n",
       "1                    NaN         NaN                        NaN    NaN  ...   \n",
       "2                    NaN         1.0                        NaN    NaN  ...   \n",
       "3                    NaN         2.0                        NaN    NaN  ...   \n",
       "4                    NaN         NaN                        NaN    NaN  ...   \n",
       "\n",
       "   Flag-Waving  Causal_Oversimplification  Slogans  Appeal_to_Authority  \\\n",
       "0          NaN                        NaN      NaN                  NaN   \n",
       "1          NaN                        NaN      NaN                  NaN   \n",
       "2          NaN                        NaN      NaN                  NaN   \n",
       "3          NaN                        NaN      NaN                  NaN   \n",
       "4          NaN                        NaN      NaN                  NaN   \n",
       "\n",
       "   Black-and-White_Fallacy  Thought-terminating_Cliches  \\\n",
       "0                      NaN                          NaN   \n",
       "1                      NaN                          NaN   \n",
       "2                      NaN                          NaN   \n",
       "3                      NaN                          NaN   \n",
       "4                      NaN                          NaN   \n",
       "\n",
       "   Whataboutism,Straw_Men,Red_Herring  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "3                                 NaN   \n",
       "4                                 NaN   \n",
       "\n",
       "   Obfuscation,Intentional_Vagueness,Confusion  \\\n",
       "0                                          NaN   \n",
       "1                                          NaN   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "   Bandwagon,Reductio_ad_hitlerum  Num Prop  \n",
       "0                             NaN       1.0  \n",
       "1                             NaN       1.0  \n",
       "2                             NaN       1.0  \n",
       "3                             NaN       2.0  \n",
       "4                             NaN       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(io.StringIO(uploaded[\"classifier_training_data.csv\"].decode('utf-8')))\n",
    "df = pd.read_csv(r'classifier_training_data.csv')\n",
    "#df = open('C:\\Users\\theot\\Downloads\\classifier_training_data.csv', \"r\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "YTKV_kw6knnp",
    "outputId": "b95f58b4-2c05-4d7e-9b79-fdeefb07c7be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Propaganda Segments</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Name_Calling,Labeling</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Exaggeration,Minimisation</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>...</th>\n",
       "      <th>Flag-Waving</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Slogans</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Black-and-White_Fallacy</th>\n",
       "      <th>Thought-terminating_Cliches</th>\n",
       "      <th>Whataboutism,Straw_Men,Red_Herring</th>\n",
       "      <th>Obfuscation,Intentional_Vagueness,Confusion</th>\n",
       "      <th>Bandwagon,Reductio_ad_hitlerum</th>\n",
       "      <th>Num Prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>On National #VoterRegistrationDay, make sure y...</td>\n",
       "      <td>we can #MakeAmericaGreatAgain: Repetition</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>Hillary Clinton's Campaign Continues To Make F...</td>\n",
       "      <td>Make False Claims: Loaded_Language</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>'CNBC, Time magazine online polls say Donald T...</td>\n",
       "      <td>MAGA: Repetition</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>In the last 24 hrs. we have raised over $13M f...</td>\n",
       "      <td>Thank you America: Repetition, \"MAGA\": Repetition</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>Well, now they're saying that I not only won t...</td>\n",
       "      <td>Nice: Loaded_Language</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    File Name Candidate  \\\n",
       "0           0  DT0_500.txt        DT   \n",
       "1           1  DT0_500.txt        DT   \n",
       "2           2  DT0_500.txt        DT   \n",
       "3           3  DT0_500.txt        DT   \n",
       "4           4  DT0_500.txt        DT   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0  On National #VoterRegistrationDay, make sure y...   \n",
       "1  Hillary Clinton's Campaign Continues To Make F...   \n",
       "2  'CNBC, Time magazine online polls say Donald T...   \n",
       "3  In the last 24 hrs. we have raised over $13M f...   \n",
       "4  Well, now they're saying that I not only won t...   \n",
       "\n",
       "                                 Propaganda Segments  Loaded_Language  \\\n",
       "0          we can #MakeAmericaGreatAgain: Repetition              0.0   \n",
       "1                 Make False Claims: Loaded_Language              1.0   \n",
       "2                                   MAGA: Repetition              0.0   \n",
       "3  Thank you America: Repetition, \"MAGA\": Repetition              0.0   \n",
       "4                              Nice: Loaded_Language              1.0   \n",
       "\n",
       "   Name_Calling,Labeling  Repetition  Exaggeration,Minimisation  Doubt  ...  \\\n",
       "0                    0.0         1.0                        0.0    0.0  ...   \n",
       "1                    0.0         0.0                        0.0    0.0  ...   \n",
       "2                    0.0         1.0                        0.0    0.0  ...   \n",
       "3                    0.0         2.0                        0.0    0.0  ...   \n",
       "4                    0.0         0.0                        0.0    0.0  ...   \n",
       "\n",
       "   Flag-Waving  Causal_Oversimplification  Slogans  Appeal_to_Authority  \\\n",
       "0          0.0                        0.0      0.0                  0.0   \n",
       "1          0.0                        0.0      0.0                  0.0   \n",
       "2          0.0                        0.0      0.0                  0.0   \n",
       "3          0.0                        0.0      0.0                  0.0   \n",
       "4          0.0                        0.0      0.0                  0.0   \n",
       "\n",
       "   Black-and-White_Fallacy  Thought-terminating_Cliches  \\\n",
       "0                      0.0                          0.0   \n",
       "1                      0.0                          0.0   \n",
       "2                      0.0                          0.0   \n",
       "3                      0.0                          0.0   \n",
       "4                      0.0                          0.0   \n",
       "\n",
       "   Whataboutism,Straw_Men,Red_Herring  \\\n",
       "0                                 0.0   \n",
       "1                                 0.0   \n",
       "2                                 0.0   \n",
       "3                                 0.0   \n",
       "4                                 0.0   \n",
       "\n",
       "   Obfuscation,Intentional_Vagueness,Confusion  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   Bandwagon,Reductio_ad_hitlerum  Num Prop  \n",
       "0                             0.0       1.0  \n",
       "1                             0.0       1.0  \n",
       "2                             0.0       1.0  \n",
       "3                             0.0       2.0  \n",
       "4                             0.0       1.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.fillna(0)## is there anywhere that shouldn't be 0 instead of NaN?\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZzP8uJz1qigq",
    "outputId": "c94fb281-9c21-4d57-deba-f946680899dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>File Name</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Propaganda Segments</th>\n",
       "      <th>Loaded_Language</th>\n",
       "      <th>Name_Calling,Labeling</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Exaggeration,Minimisation</th>\n",
       "      <th>Doubt</th>\n",
       "      <th>...</th>\n",
       "      <th>Causal_Oversimplification</th>\n",
       "      <th>Slogans</th>\n",
       "      <th>Appeal_to_Authority</th>\n",
       "      <th>Black-and-White_Fallacy</th>\n",
       "      <th>Thought-terminating_Cliches</th>\n",
       "      <th>Whataboutism,Straw_Men,Red_Herring</th>\n",
       "      <th>Obfuscation,Intentional_Vagueness,Confusion</th>\n",
       "      <th>Bandwagon,Reductio_ad_hitlerum</th>\n",
       "      <th>Num Prop</th>\n",
       "      <th>BCandidate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>On National #VoterRegistrationDay, make sure y...</td>\n",
       "      <td>we can #MakeAmericaGreatAgain: Repetition</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>Hillary Clinton's Campaign Continues To Make F...</td>\n",
       "      <td>Make False Claims: Loaded_Language</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>'CNBC, Time magazine online polls say Donald T...</td>\n",
       "      <td>MAGA: Repetition</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>In the last 24 hrs. we have raised over $13M f...</td>\n",
       "      <td>Thank you America: Repetition, \"MAGA\": Repetition</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DT0_500.txt</td>\n",
       "      <td>DT</td>\n",
       "      <td>Well, now they're saying that I not only won t...</td>\n",
       "      <td>Nice: Loaded_Language</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>3500</td>\n",
       "      <td>HC500_1000.txt</td>\n",
       "      <td>HC</td>\n",
       "      <td>Housing discrimination cuts right to the heart...</td>\n",
       "      <td>Housing discrimination cuts right to the heart...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>3501</td>\n",
       "      <td>HC500_1000.txt</td>\n",
       "      <td>HC</td>\n",
       "      <td>Here's a pretty incredible fact: There is a no...</td>\n",
       "      <td>pretty incredible: Loaded_Language, \"There is ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>3502</td>\n",
       "      <td>HC500_1000.txt</td>\n",
       "      <td>HC</td>\n",
       "      <td>Here's why Donald Trump might be refusing to r...</td>\n",
       "      <td>Donald Trump might be refusing to release his ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>3503</td>\n",
       "      <td>HC500_1000.txt</td>\n",
       "      <td>HC</td>\n",
       "      <td>Why is @realDonaldTrump refusing to release hi...</td>\n",
       "      <td>Why is @realDonaldTrump refusing to release hi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>3504</td>\n",
       "      <td>HC500_1000.txt</td>\n",
       "      <td>HC</td>\n",
       "      <td>Trump wants America to work for him and his fr...</td>\n",
       "      <td>We’re all so proud of you: Slogans, \"Trump wan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3505 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       File Name Candidate  \\\n",
       "0              0     DT0_500.txt        DT   \n",
       "1              1     DT0_500.txt        DT   \n",
       "2              2     DT0_500.txt        DT   \n",
       "3              3     DT0_500.txt        DT   \n",
       "4              4     DT0_500.txt        DT   \n",
       "...          ...             ...       ...   \n",
       "3500        3500  HC500_1000.txt        HC   \n",
       "3501        3501  HC500_1000.txt        HC   \n",
       "3502        3502  HC500_1000.txt        HC   \n",
       "3503        3503  HC500_1000.txt        HC   \n",
       "3504        3504  HC500_1000.txt        HC   \n",
       "\n",
       "                                               Sentence  \\\n",
       "0     On National #VoterRegistrationDay, make sure y...   \n",
       "1     Hillary Clinton's Campaign Continues To Make F...   \n",
       "2     'CNBC, Time magazine online polls say Donald T...   \n",
       "3     In the last 24 hrs. we have raised over $13M f...   \n",
       "4     Well, now they're saying that I not only won t...   \n",
       "...                                                 ...   \n",
       "3500  Housing discrimination cuts right to the heart...   \n",
       "3501  Here's a pretty incredible fact: There is a no...   \n",
       "3502  Here's why Donald Trump might be refusing to r...   \n",
       "3503  Why is @realDonaldTrump refusing to release hi...   \n",
       "3504  Trump wants America to work for him and his fr...   \n",
       "\n",
       "                                    Propaganda Segments  Loaded_Language  \\\n",
       "0             we can #MakeAmericaGreatAgain: Repetition              0.0   \n",
       "1                    Make False Claims: Loaded_Language              1.0   \n",
       "2                                      MAGA: Repetition              0.0   \n",
       "3     Thank you America: Repetition, \"MAGA\": Repetition              0.0   \n",
       "4                                 Nice: Loaded_Language              1.0   \n",
       "...                                                 ...              ...   \n",
       "3500  Housing discrimination cuts right to the heart...              0.0   \n",
       "3501  pretty incredible: Loaded_Language, \"There is ...              1.0   \n",
       "3502  Donald Trump might be refusing to release his ...              0.0   \n",
       "3503  Why is @realDonaldTrump refusing to release hi...              0.0   \n",
       "3504  We’re all so proud of you: Slogans, \"Trump wan...              0.0   \n",
       "\n",
       "      Name_Calling,Labeling  Repetition  Exaggeration,Minimisation  Doubt  \\\n",
       "0                       0.0         1.0                        0.0    0.0   \n",
       "1                       0.0         0.0                        0.0    0.0   \n",
       "2                       0.0         1.0                        0.0    0.0   \n",
       "3                       0.0         2.0                        0.0    0.0   \n",
       "4                       0.0         0.0                        0.0    0.0   \n",
       "...                     ...         ...                        ...    ...   \n",
       "3500                    0.0         0.0                        0.0    0.0   \n",
       "3501                    0.0         0.0                        0.0    0.0   \n",
       "3502                    0.0         0.0                        0.0    1.0   \n",
       "3503                    0.0         0.0                        0.0    1.0   \n",
       "3504                    0.0         0.0                        0.0    0.0   \n",
       "\n",
       "      ...  Causal_Oversimplification  Slogans  Appeal_to_Authority  \\\n",
       "0     ...                        0.0      0.0                  0.0   \n",
       "1     ...                        0.0      0.0                  0.0   \n",
       "2     ...                        0.0      0.0                  0.0   \n",
       "3     ...                        0.0      0.0                  0.0   \n",
       "4     ...                        0.0      0.0                  0.0   \n",
       "...   ...                        ...      ...                  ...   \n",
       "3500  ...                        0.0      0.0                  0.0   \n",
       "3501  ...                        0.0      0.0                  0.0   \n",
       "3502  ...                        0.0      0.0                  0.0   \n",
       "3503  ...                        0.0      0.0                  0.0   \n",
       "3504  ...                        0.0      1.0                  0.0   \n",
       "\n",
       "      Black-and-White_Fallacy  Thought-terminating_Cliches  \\\n",
       "0                         0.0                          0.0   \n",
       "1                         0.0                          0.0   \n",
       "2                         0.0                          0.0   \n",
       "3                         0.0                          0.0   \n",
       "4                         0.0                          0.0   \n",
       "...                       ...                          ...   \n",
       "3500                      0.0                          0.0   \n",
       "3501                      0.0                          0.0   \n",
       "3502                      0.0                          0.0   \n",
       "3503                      0.0                          0.0   \n",
       "3504                      0.0                          0.0   \n",
       "\n",
       "      Whataboutism,Straw_Men,Red_Herring  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "...                                  ...   \n",
       "3500                                 0.0   \n",
       "3501                                 0.0   \n",
       "3502                                 0.0   \n",
       "3503                                 0.0   \n",
       "3504                                 0.0   \n",
       "\n",
       "      Obfuscation,Intentional_Vagueness,Confusion  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "...                                           ...   \n",
       "3500                                          0.0   \n",
       "3501                                          0.0   \n",
       "3502                                          0.0   \n",
       "3503                                          0.0   \n",
       "3504                                          0.0   \n",
       "\n",
       "      Bandwagon,Reductio_ad_hitlerum  Num Prop  BCandidate  \n",
       "0                                0.0       1.0           1  \n",
       "1                                0.0       1.0           1  \n",
       "2                                0.0       1.0           1  \n",
       "3                                0.0       2.0           1  \n",
       "4                                0.0       1.0           1  \n",
       "...                              ...       ...         ...  \n",
       "3500                             0.0       1.0           0  \n",
       "3501                             0.0       2.0           0  \n",
       "3502                             0.0       1.0           0  \n",
       "3503                             0.0       1.0           0  \n",
       "3504                             0.0       2.0           0  \n",
       "\n",
       "[3505 rows x 22 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.assign(\n",
    "   # is_senior = lambda dataframe: dataframe['age'].map(lambda age: True if age >= 65 else False)\n",
    "\n",
    "df =df.assign(\n",
    "    BCandidate = lambda dataframe : dataframe['Candidate'].map(lambda Candidate: 1 if Candidate == \"DT\" else 0)\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LF--4qZV0Wq0",
    "outputId": "eff77dd4-fb95-4d21-ff36-4c34bbb9dd46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC length:  1522\n",
      "DT length:  1983\n",
      "DT length ratio:  0.4948839530821063\n"
     ]
    }
   ],
   "source": [
    "dfH = df.loc[df['Candidate']=='HC',:]\n",
    "print(\"HC length: \",len(dfH))\n",
    "\n",
    "dfT =df.loc[df['Candidate']=='DT',:]\n",
    "print(\"DT length: \",len(dfT))\n",
    "#print(.5*(len(dfT)/len(dfH)))\n",
    "\n",
    "df_new = df\n",
    "\n",
    "#df_new = df.append(dfH)\n",
    "#df_new = df_new.append(dfH)\n",
    "df_new = df_new.append(dfH[:math.floor(len(dfH)*.33)])\n",
    "print(\"DT length ratio: \",len(dfT)/len(df_new))\n",
    "\n",
    "df = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC length:  2024\n",
      "DT length:  1983\n"
     ]
    }
   ],
   "source": [
    "dfH = df.loc[df['Candidate']=='HC',:]\n",
    "print(\"HC length: \",len(dfH))\n",
    "\n",
    "dfT =df.loc[df['Candidate']=='DT',:]\n",
    "print(\"DT length: \",len(dfT))\n",
    "#print(.5*(len(dfT)/len(dfH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tesing prop types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "HslAmZV_kngx"
   },
   "outputs": [],
   "source": [
    "\n",
    "#array = df_0.values\n",
    "\n",
    "#X = array[:,5:14 ]## what if I want to select by the names of the column not the index? \n",
    "#Y = array[: , 2]\n",
    "X = df.loc[:,'Loaded_Language':'Bandwagon,Reductio_ad_hitlerum',]\n",
    "Y = df.loc[:,\"BCandidate\"]\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = .2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-sNKCwaknY0",
    "outputId": "53c1e5fd-9c4f-4182-9c3d-b7a5b06646aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.654251112979048, 0.654251112979048, 0.6530462937019395, 0.6155163288814172, 0.5, 0.5]\n",
      "[0.6533665835411472, 0.6533665835411472, 0.6521197007481296, 0.6209476309226932, 0.5174563591022444, 0.4825436408977556]\n",
      "[array([[261, 154],\n",
      "       [124, 263]], dtype=int64), array([[261, 154],\n",
      "       [124, 263]], dtype=int64), array([[260, 155],\n",
      "       [124, 263]], dtype=int64), array([[320,  95],\n",
      "       [209, 178]], dtype=int64), array([[415,   0],\n",
      "       [387,   0]], dtype=int64), array([[  0, 415],\n",
      "       [  0, 387]], dtype=int64)]\n",
      "[array([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64), array([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
      "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "       1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
      "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "       0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0], dtype=int64), array([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
      "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
      "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
      "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
      "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
      "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "## repeat rows for HC so that we have even DT and HC doccumnents \n",
    "\n",
    "## ML models \n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "\n",
    "#models.append(('LASSO', linear_model.Lasso(alpha=.1)))## this doesn't play nicely with my loop\n",
    "# add lassau or ridgid regression - regularization with penalty terms - play around with the ammount of penalty \n",
    "models.append(('SVM', SVC(gamma='auto'))) # support vector machine\n",
    "#try different kernals for SVC\n",
    "models.append(('ETC', ExtraTreesClassifier(n_estimators=100, random_state=0))) ## dont need make_classifier?\n",
    "models.append(('RFC', RandomForestClassifier(max_depth= 2, random_state = 0))) ## branching patterns and depth parameters - random forest is a type of decision tree \n",
    "# create a tensor full of results based on different parameters - do a grid search \n",
    "# make \"model_results\" file - dynamic names \n",
    "#could paralelize these operations - maybe not worth the time \n",
    "models.append(('null0', DummyRegressor(strategy=\"constant\", constant= 0)))\n",
    "models.append(('null1', DummyRegressor(strategy=\"constant\", constant= 1)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "roc_auc= []\n",
    "fitted_mods=[]\n",
    "conf_mat= []\n",
    "predictions = []\n",
    "for name, model in models: \n",
    "\tfitted_mods.append(model.fit(X_train, Y_train))\n",
    " \n",
    "\tnames.append(name)\n",
    " \n",
    "roc_auc\n",
    "\n",
    "for i in fitted_mods: \n",
    "\troc_auc.append(roc_auc_score(Y_test,i.predict(X_test)))\n",
    "\tresults.append(accuracy_score(Y_test, i.predict(X_test)))\n",
    "\n",
    "\tconf_mat.append(confusion_matrix(Y_test, i.predict(X_test)))\n",
    " \n",
    "\tpredictions.append(i.predict(X_test))\n",
    " \n",
    "print(roc_auc)\n",
    "print(results)\n",
    "print(conf_mat)\n",
    "print(predictions)\n",
    "\n",
    "#for name, model in models:\n",
    "#\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)# what does this do?\n",
    "#\tcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')# I think this is like bootstraping\n",
    "#\troc_auc.append( cross_val_score(model, X_train, Y_train, cv=kfold, scoring='roc_auc'))\n",
    "#\tresults.append(cv_results)\n",
    "#\tnames.append(name)\n",
    "\t\n",
    "#\tmods.append(model.fit(X_train,Y_train))\n",
    "\n",
    "\n",
    "## one loop to train the model and then save them \n",
    "# find the results and save them \n",
    "\n",
    "#\n",
    "\t#print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()),)\n",
    "\n",
    "\n",
    "\n",
    " #https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "rbchzFUI1V6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(gamma='auto'),\n",
       "             param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,\n",
       "                               15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "                               27, 28, 29],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']})"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# support vector machine\n",
    "\n",
    "SVCCV = GridSearchCV(\n",
    "SVC(gamma='auto'), param_grid = { \n",
    "    'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C' : list(range(1,30))\n",
    "\n",
    "\n",
    "})\n",
    "\n",
    "SVCCV.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'SVC_GS'\n",
    "pickle.dump(SVCCV, open(filename,'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6521197007481296\n"
     ]
    }
   ],
   "source": [
    "##reading in trained model\n",
    "\n",
    "filename = 'SVC_GS'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "1BwJMTvrtlfp",
    "outputId": "928ccc21-4095-4c15-a671-f6cd4d295d22"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11084/1949495523.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m ETCV = GridSearchCV(ExtraTreesClassifier(),param_grid = {\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;34m'n_estimators'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m# no real benefit from 1,100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;34m'random_state'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "## gridsearch\n",
    "#https://www.youtube.com/watch?v=HdlDYng8g9s&t=20s\n",
    "\n",
    "#n_estimators=100, random_state=0)\n",
    "\n",
    "\n",
    "ETCV = GridSearchCV(ExtraTreesClassifier(),param_grid = {\n",
    "    'n_estimators' : list(range(1,100,10)),# no real benefit from 1,100\n",
    "    'random_state' : list(range(1,100,10))\n",
    "})\n",
    "\n",
    "ETCV.fit(X_train,Y_train)\n",
    "ETCV.cv_results_\n",
    "\n",
    "CVdf = pd.DataFrame(ETCV.cv_results_)\n",
    "#CVdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g33rcBGZCARB",
    "outputId": "6632292a-d69e-400d-f6eb-cc618cc68b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6530462937019395\n"
     ]
    }
   ],
   "source": [
    "CVdf.loc[:,\"mean_test_score\"].max()\n",
    "print(roc_auc_score(Y_test,ETCV.predict(X_test)))\n",
    "filename = 'extra_trees_GS'\n",
    "pickle.dump(ETCV, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "FaCfle5hClWf",
    "outputId": "667628e2-4288-4305-bcc1-11a2143cea33"
   },
   "outputs": [],
   "source": [
    "#models.append(('RFC', RandomForestClassifier(max_depth= 2, random_state = 0)))\n",
    "RFCV = GridSearchCV(RandomForestClassifier(), param_grid={ \n",
    "    'n_estimators' : list(range(1,100,10)),\n",
    "    'max_depth': list(range(2,100,10)),\n",
    "    'random_state': list(range(10,100,10))\n",
    "\n",
    "})\n",
    "RFCV.fit(X_train,Y_train)\n",
    "\n",
    "RFCV.cv_results_\n",
    "\n",
    "RFCVdf = pd.DataFrame(RFCV.cv_results_)\n",
    "\n",
    "#RFCVdf\n",
    "## took over an hour to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNJylrl-D7gR",
    "outputId": "55790afc-c56c-424f-b8e8-004c85cce6aa"
   },
   "outputs": [],
   "source": [
    "print(RFCVdf.loc[:,\"mean_test_score\"].max())\n",
    "print(roc_auc_score(Y_test,RFCV.predict(X_test)))\n",
    "\n",
    "filename = 'RFCV_GS'\n",
    "pickle.dump(RFCV, open(filename,'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWT73NtMrw5i"
   },
   "outputs": [],
   "source": [
    "## saving the models \n",
    "import pickle\n",
    "\n",
    "for i in range(len(fitted_mods)): \n",
    "  filename = 'fitted_model' + names[i]\n",
    "  pickle.dump(fitted_mods[i], open(filename,'wb'))\n",
    "\n",
    "#https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "1rG45Iq2-RHs",
    "outputId": "6fc67147-183b-499f-9942-7e75ed65c49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedReader name='fitted_modelSVM'>\n"
     ]
    }
   ],
   "source": [
    "#file_ptr = open(\"fitted_model\"+names[1],'rb')\n",
    "#print(file_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkyRRz3KsWRo",
    "outputId": "a249f7dc-2089-4000-c8f9-eea97c8e2fff"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVoMs9qM-tED"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OKO3H0tw1aCr",
    "outputId": "dbef4dff-0f9b-4e6b-bf53-8921620d5be7"
   },
   "outputs": [],
   "source": [
    "## printing imporant stats\n",
    "for i in range(len(names)):\n",
    "  print(names[i],'accuracy:' , results[i], 'roc auc:',roc_auc[i])\n",
    "  cm = confusion_matrix(Y_test,predictions[i])\n",
    "  ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKPh2evzxLEw",
    "outputId": "97e4d46b-c6c1-45aa-a7d2-a6718ca4aeb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0032481054983333644\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#Lasso\n",
    "\n",
    "#linear_model.Lasso(alpha=.1))## this doesn't play nicely with my loop\n",
    "LOCV = GridSearchCV( linear_model.Lasso(), param_grid={ \n",
    "    'alpha' : list(np.arange (.1, 50, .1))\n",
    "\n",
    "})\n",
    "LOCV.fit(X_train,Y_train)\n",
    "LOCV.cv_results_\n",
    "\n",
    "LOCVdf = pd.DataFrame(LOCV.cv_results_)\n",
    "\n",
    "LOCVdf\n",
    "\n",
    "print(LOCVdf.loc[:,\"mean_test_score\"].max())\n",
    "print(roc_auc_score(Y_test,LOCV.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(LOCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0032481054983333644\n",
      "0.6531334640889137\n"
     ]
    }
   ],
   "source": [
    "NNCV = GridSearchCV( MLPClassifier(), param_grid={ \n",
    "    'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha' : [1e-5,1e-4,1e-3,1e-2]\n",
    "    \n",
    "\n",
    "})\n",
    "NNCV.fit(X_train,Y_train)\n",
    "NNCV.cv_results_\n",
    "\n",
    "NNCVdf = pd.DataFrame(LOCV.cv_results_)\n",
    "\n",
    "NNCVdf\n",
    "\n",
    "print(NNCVdf.loc[:,\"mean_test_score\"].max())\n",
    "print(roc_auc_score(Y_test,NNCV.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bY9wCEL6yr7s",
    "outputId": "28bc6fef-2c6c-4a3a-a349-919f2b5a5f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6530462937019395\n"
     ]
    }
   ],
   "source": [
    "## neural networks: Class MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation. \n",
    "## should I use gridsearchCV on this? there are so many parameters! \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "MLPNN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=200000)\n",
    "\n",
    "MLPNN.fit(X_train, Y_train)\n",
    "\n",
    "print(roc_auc_score(Y_test,MLPNN.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each histogram plot DT v HC feature importance - plot them side by side \n",
    "#x axis - prop techinuqes \n",
    "# y is frequency with whcih the propaganda technique is used in each tweet\n",
    "# with box plot mark the mean median and quartiles.\n",
    "## test statistical signifigance\n",
    "# check whether there is a statistical difference - use a test without normal data assumption.\n",
    "## do this for tweets only \n",
    "# not tweet data \n",
    "# all data \n",
    "\n",
    "\n",
    "# look if there is a data set for their speaches \n",
    "\n",
    "#https://www.presidency.ucsb.edu/documents/remarks-the-cnn-democratic-presidential-town-hall-derry-new-hampshire\n",
    "## scrape this data and run it through the model. - crawl the website- just grab everything! we might want to see other candidates.\n",
    "\n",
    "## get data from 2013.\n",
    "## look at commoncrawl.org\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "oMqcXjzr7eK1",
    "outputId": "561fabe4-de8c-4ff6-cd77-ebbab5b377ae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## importance on extra trees\n",
    "importances= fitted_mods[2].feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in fitted_mods[2].estimators_], axis=0)\n",
    "\n",
    "\n",
    "forest_importances = pd.Series(importances)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importance is calculated by suffling a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "mfONCGsIxPSv",
    "outputId": "ec35fe70-56d9-4fac-99af-49377aafbe93"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## importantce on RandomForest\n",
    "\n",
    "importances= fitted_mods[3].feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in fitted_mods[3].estimators_], axis=0)\n",
    "\n",
    "\n",
    "forest_importances = pd.Series(importances)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "95n03DPKx942",
    "outputId": "30f5496a-9ea2-44fb-e7ee-7dfd42a03de1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mods' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-13e743d935ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mworking\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmods\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mworking_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworking_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mods' is not defined"
     ]
    }
   ],
   "source": [
    "#https://www.youtube.com/watch?v=uVJXPPrWRJ0\n",
    "#source^\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "working =mods[0]\n",
    "working_probs = working.predict_proba(X_test)\n",
    "print(working_probs)\n",
    "working_probs = working_probs[:,0]## not sure why we do this \n",
    "working_AUC = roc_auc_score(Y_test,working_probs)\n",
    "print(working_AUC)\n",
    "\n",
    "probs = []\n",
    "'''\n",
    "for i in range(len(mods)):\n",
    "  M = mods[i]\n",
    "  M_probs = M.predict_proba(X_test)## this doesn't work for one of the tests.\n",
    "  M_probs = M_probs[:,1]## not sure why we do this \n",
    "  M_AUC = roc_auc_score(Y_test,M_probs)\n",
    "  print(working_AUC)\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "BCP0cVwpowtQ",
    "outputId": "a03c95de-9aec-4a0b-b61e-bbf6571afb52"
   },
   "outputs": [],
   "source": [
    "pyplot.boxplot(results, labels=names)\n",
    "pyplot.title('Algorithm Comparison')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Bs3SGEz0M_J"
   },
   "source": [
    "Make sure we save the results \n",
    "- "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML models 11/5/21",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
